# Real-Time Kernel for Openshift4.9

本次试验部署架构图

![](../4.7/dia/4.7.real-time.kernel.drawio.svg)

opened case for baiceill testing:
- https://access.redhat.com/support/cases/#/case/02991973
- https://bugzilla.redhat.com/show_bug.cgi?id=1984933

# 硬件部署

baicell方案有专属的FPGA，每个FPGA可以连4个RRU，如果连RHUB，可以连4个RHUB，每个RHUB连8个RRU，那么最终可以连接32个RRU，另外GPS连接也是在FPGA上。

# 先使用performance addon operator，这个是官方推荐的方法。

performance addon operator 是openshift4里面的一个operator，他的作用是，让用户进行简单的yaml配置，然后operator帮助客户进行复杂的kernel parameter, kubelet, tuned配置。

```bash

# install performance addon operator following offical document
# https://docs.openshift.com/container-platform/4.9/scalability_and_performance/cnf-performance-addon-operator-for-low-latency-nodes.html

cat << EOF > /data/install/pao-namespace.yaml
---
apiVersion: v1
kind: Namespace
metadata:
  name: openshift-performance-addon-operator
  annotations:
    workload.openshift.io/allowed: management
---
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: openshift-performance-addon-operator
  namespace: openshift-performance-addon-operator
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: openshift-performance-addon-operator-subscription
  namespace: openshift-performance-addon-operator
spec:
  channel: "4.9" 
  name: performance-addon-operator
  source: redhat-operators 
  sourceNamespace: openshift-marketplace
EOF
oc create -f /data/install/pao-namespace.yaml

# then check pao in project openshift-performance-addon-operator
# using webUI

# 以下的配置，是保留了0-1核给系统，剩下的2-19核给应用。
cat << EOF > /data/install/performance.yaml
apiVersion: performance.openshift.io/v2
kind: PerformanceProfile
metadata:
   name: wzh-performanceprofile
spec:
  additionalKernelArgs:
    - no_timer_check
    - clocksource=tsc
    - tsc=perfect
    # - selinux=0
    # - enforcing=0
    - nmi_watchdog=0
    - softlockup_panic=0
    - isolcpus=2-19
    - nohz_full=2-19
    - idle=poll
    - default_hugepagesz=1G
    - hugepagesz=1G
    - hugepages=16
    - skew_tick=1
    - rcu_nocbs=2-19
    - kthread_cpus=0-1
    - irqaffinity=0-1
    - rcu_nocb_poll
    - iommu=pt
    - intel_iommu=on
    # profile creator
    - audit=0
    - idle=poll
    - intel_idle.max_cstate=0
    - mce=off
    - nmi_watchdog=0
    - nosmt
    - processor.max_cstate=1
  globallyDisableIrqLoadBalancing: true
  cpu:
      isolated: "2-19"
      reserved: "0-1"
  realTimeKernel:
      enabled: true
  numa:  
      topologyPolicy: "single-numa-node"
  nodeSelector:
      node-role.kubernetes.io/master: ""
  machineConfigPoolSelector:
    pools.operator.machineconfiguration.openshift.io/master: ""
EOF
oc create -f /data/install/performance.yaml

# it will create following
  # runtimeClass: performance-wzh-performanceprofile
  # tuned: >-
  #   openshift-cluster-node-tuning-operator/openshift-node-performance-wzh-performanceprofile

oc get mc/50-nto-worker-rt -o yaml
oc get runtimeClass -o yaml
oc get -n openshift-cluster-node-tuning-operator tuned/openshift-node-performance-wzh-performanceprofile -o yaml

# restore
oc delete -f /data/install/performance.yaml

# 一般都需要 cpu/numa 绑核，这个在 kubelet 的配置里面做
# cat << EOF > /data/install/cpumanager-kubeletconfig.yaml
# apiVersion: machineconfiguration.openshift.io/v1
# kind: KubeletConfig
# metadata:
#   name: cpumanager-enabled
# spec:
#   machineConfigPoolSelector:
#     matchLabels:
#       custom-kubelet: cpumanager-enabled
#   kubeletConfig:
#      cpuManagerPolicy: static 
#      cpuManagerReconcilePeriod: 5s 
#      topologyManagerPolicy: single-numa-node 
#      reservedSystemCPUs: "0,1" 
# EOF
# oc create -f  /data/install/cpumanager-kubeletconfig.yaml

# enable sctp
# https://docs.openshift.com/container-platform/4.9/networking/using-sctp.html
cat << EOF > /data/install/sctp-module.yaml
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfig
metadata:
  name: 99-master-rt-load-sctp-module
  labels:
    machineconfiguration.openshift.io/role: master
spec:
  config:
    ignition:
      version: 3.2.0
    storage:
      files:
        - path: /etc/modprobe.d/sctp-blacklist.conf
          mode: 0644
          overwrite: true
          contents:
            source: data:,
        - path: /etc/modules-load.d/sctp-load.conf
          mode: 0644
          overwrite: true
          contents:
            source: data:,sctp
EOF
oc create -f /data/install/sctp-module.yaml

# to restore
oc delete -f /data/install/sctp-module.yaml

# check the result
ssh core@master-0
uname -a
# Linux worker-0 4.18.0-193.51.1.rt13.101.el8_2.x86_64 #1 SMP PREEMPT RT Thu Apr 8 17:21:44 EDT 2021 x86_64 x86_64 x86_64 GNU/Linux

ps -ef | grep stalld
# root       16212       1  0 13:20 ?        00:00:00 /usr/local/bin/stalld --systemd -p 1000000000 -r 10000 -d 3 -t 20 --log_syslog --log_kmsg --foreground --pidfile /run/stalld.pid
# core        6601    6478  0 14:08 pts/0    00:00:00 grep --color=auto stalld

```

# performance addon operator for HT

```bash
# first check cpu / thread binding
lscpu  --all --extended
# CPU NODE SOCKET CORE L1d:L1i:L2:L3 ONLINE MAXMHZ    MINMHZ
# 0   0    0      0    0:0:0:0       yes    2500.0000 1000.0000
# 1   0    0      1    1:1:1:0       yes    2500.0000 1000.0000
# 2   0    0      2    2:2:2:0       yes    2500.0000 1000.0000
# 3   0    0      3    3:3:3:0       yes    2500.0000 1000.0000
# 4   0    0      4    4:4:4:0       yes    2500.0000 1000.0000
# 5   0    0      5    5:5:5:0       yes    2500.0000 1000.0000
# 6   0    0      6    6:6:6:0       yes    2500.0000 1000.0000
# 7   0    0      7    7:7:7:0       yes    2500.0000 1000.0000
# 8   0    0      8    8:8:8:0       yes    2500.0000 1000.0000
# 9   0    0      9    9:9:9:0       yes    2500.0000 1000.0000
# 10  0    0      10   10:10:10:0    yes    2500.0000 1000.0000
# 11  0    0      11   11:11:11:0    yes    2500.0000 1000.0000
# 12  0    0      12   12:12:12:0    yes    2500.0000 1000.0000
# 13  0    0      13   13:13:13:0    yes    2500.0000 1000.0000
# 14  0    0      14   14:14:14:0    yes    2500.0000 1000.0000
# 15  0    0      15   15:15:15:0    yes    2500.0000 1000.0000
# 16  0    0      16   16:16:16:0    yes    2500.0000 1000.0000
# 17  0    0      17   17:17:17:0    yes    2500.0000 1000.0000
# 18  0    0      18   18:18:18:0    yes    2500.0000 1000.0000
# 19  0    0      19   19:19:19:0    yes    2500.0000 1000.0000
# 20  0    0      0    0:0:0:0       yes    2500.0000 1000.0000
# 21  0    0      1    1:1:1:0       yes    2500.0000 1000.0000
# 22  0    0      2    2:2:2:0       yes    2500.0000 1000.0000
# 23  0    0      3    3:3:3:0       yes    2500.0000 1000.0000
# 24  0    0      4    4:4:4:0       yes    2500.0000 1000.0000
# 25  0    0      5    5:5:5:0       yes    2500.0000 1000.0000
# 26  0    0      6    6:6:6:0       yes    2500.0000 1000.0000
# 27  0    0      7    7:7:7:0       yes    2500.0000 1000.0000
# 28  0    0      8    8:8:8:0       yes    2500.0000 1000.0000
# 29  0    0      9    9:9:9:0       yes    2500.0000 1000.0000
# 30  0    0      10   10:10:10:0    yes    2500.0000 1000.0000
# 31  0    0      11   11:11:11:0    yes    2500.0000 1000.0000
# 32  0    0      12   12:12:12:0    yes    2500.0000 1000.0000
# 33  0    0      13   13:13:13:0    yes    2500.0000 1000.0000
# 34  0    0      14   14:14:14:0    yes    2500.0000 1000.0000
# 35  0    0      15   15:15:15:0    yes    2500.0000 1000.0000
# 36  0    0      16   16:16:16:0    yes    2500.0000 1000.0000
# 37  0    0      17   17:17:17:0    yes    2500.0000 1000.0000
# 38  0    0      18   18:18:18:0    yes    2500.0000 1000.0000
# 39  0    0      19   19:19:19:0    yes    2500.0000 1000.0000

# 以下的配置，是保留了0-1核给系统，剩下的2-39核给应用。
cat << EOF > /data/install/performance.yaml
apiVersion: performance.openshift.io/v2
kind: PerformanceProfile
metadata:
   name: wzh-performanceprofile
spec:
  additionalKernelArgs:
    - no_timer_check
    - clocksource=tsc
    - tsc=perfect
    # - selinux=0
    # - enforcing=0
    - nmi_watchdog=0
    - softlockup_panic=0
    - isolcpus=2-19,22-39
    - nohz_full=2-19,22-39
    - idle=poll
    - default_hugepagesz=1G
    - hugepagesz=1G
    - hugepages=10
    - skew_tick=1
    - rcu_nocbs=2-19,22-39
    - kthread_cpus=0-1,20-21
    - irqaffinity=0-1,20-21
    - rcu_nocb_poll
    - iommu=pt
    - intel_iommu=on
    # profile creator
    - audit=0
    - idle=poll
    - intel_idle.max_cstate=0
    - mce=off
    - nmi_watchdog=0
    # - nosmt
    - processor.max_cstate=1
  globallyDisableIrqLoadBalancing: true
  cpu:
      isolated: "2-19,22-39"
      reserved: "0-1,20-21"
  realTimeKernel:
      enabled: true
  numa:  
      topologyPolicy: "single-numa-node"
  nodeSelector:
      node-role.kubernetes.io/master: ""
  machineConfigPoolSelector:
    pools.operator.machineconfiguration.openshift.io/master: ""
EOF
oc create -f /data/install/performance.yaml

# to restore
oc delete -f /data/install/performance.yaml

cat << EOF > /data/install/sctp-module.yaml
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfig
metadata:
  name: 99-master-rt-load-sctp-module
  labels:
    machineconfiguration.openshift.io/role: master
spec:
  config:
    ignition:
      version: 3.2.0
    storage:
      files:
        - path: /etc/modprobe.d/sctp-blacklist.conf
          mode: 0644
          overwrite: true
          contents:
            source: data:,
        - path: /etc/modules-load.d/sctp-load.conf
          mode: 0644
          overwrite: true
          contents:
            source: data:,sctp
EOF
oc create -f /data/install/sctp-module.yaml

# to restore
oc delete -f /data/install/sctp-module.yaml

```


# create vBBU app
```yaml
---

apiVersion: "k8s.cni.cncf.io/v1"
kind: NetworkAttachmentDefinition
metadata:
  name: host-device-du
spec:
  config: '{
    "cniVersion": "0.3.0",
    "type": "host-device",
    "device": "ens18f1",
    "ipam": {
      "type": "host-local",
      "subnet": "192.168.12.0/24",
      "rangeStart": "192.168.12.105",
      "rangeEnd": "192.168.12.106",
      "routes": [{
        "dst": "0.0.0.0/0"
      }],
      "gateway": "192.168.12.1"
    }
  }'

# apiVersion: "k8s.cni.cncf.io/v1"
# kind: NetworkAttachmentDefinition
# metadata:
#   name: host-device-du
# spec:
#   config: '{
#     "cniVersion": "0.3.0",
#     "type": "host-device",
#     "device": "ens18f1",
#     "ipam": {
#       "type": "static",
#       "addresses": [ 
#             {
#               "address": "192.168.12.105/24"
#             },
#             {
#               "address": "192.168.12.106/24"
#             }
#           ],
#       "routes": [ 
#           {
#             "dst": "0.0.0.0/0", 
#             "gw": "192.168.12.1"
#           }
#         ]
#       }
#     }'


---

apiVersion: apps/v1
kind: Deployment
metadata:
  name: du-deployment1
  labels:
    app: du-deployment1
spec:
  replicas: 1
  selector:
    matchLabels:
      app: du-pod1
  template:
    metadata:
      labels:
        app: du-pod1
      annotations:
        k8s.v1.cni.cncf.io/networks: '[
          { "name": "host-device-du",
            "interface": "veth11" }
          ]'
      cpu-load-balancing.crio.io: "true"
    spec:
      runtimeClassName: performance-wzh-performanceprofile
      containers:
      - name: du-container1
        image: "registry.ocp4.redhat.ren:5443/ocp4/du:v1-wzh-shell-03"
        imagePullPolicy: IfNotPresent
        tty: true
        stdin: true
        env:
          - name: duNetProviderDriver
            value: "host-netdevice"
        #command:
        #  - sleep
        #  - infinity
        securityContext:
            privileged: true
            capabilities:
                add:
                - CAP_SYS_ADMIN
        volumeMounts:
          - mountPath: /hugepages
            name: hugepage
          - name: lib-modules
            mountPath: /lib/modules
          - name: src
            mountPath: /usr/src
          - name: dev
            mountPath: /dev
          - name: cache-volume
            mountPath: /dev/shm
        resources:
          requests:
            cpu: 16
            memory: 48Gi
            hugepages-1Gi: 8Gi
          limits:
            cpu: 16
            memory: 48Gi
            hugepages-1Gi: 8Gi
      volumes:
        - name: hugepage
          emptyDir:
            medium: HugePages
        - name: lib-modules
          hostPath:
            path: /lib/modules
        - name: src
          hostPath:
            path: /usr/src
        - name: dev
          hostPath:
            path: "/dev"
        - name: cache-volume
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi
      nodeSelector:
        node-role.kubernetes.io/worker-rt: ""

---

# apiVersion: v1
# kind: Service
# metadata:
#   name: du-http 
# spec:
#   ports:
#   - name: http
#     port: 80
#     targetPort: 80 
#   type: NodePort 
#   selector:
#     app: du-pod1

---

```

# RIC 

```bash

# then create mcp, be careful, the label must be there
cat << EOF > /data/install/worker-ric.yaml
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfigPool
metadata:
  name: worker-ric
  labels:
    machineconfiguration.openshift.io/role: worker-ric
spec:
  machineConfigSelector:
    matchExpressions:
      - {key: machineconfiguration.openshift.io/role, operator: In, values: [worker,worker-ric]}
  nodeSelector:
    matchLabels:
      node-role.kubernetes.io/worker-ric: ""

EOF
oc create -f /data/install/worker-ric.yaml

# to restore
oc delete -f /data/install/worker-ric.yaml

oc label node worker-1 node-role.kubernetes.io/worker-ric=""

# enable sctp
cat << EOF > /data/install/sctp-module-ric.yaml
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfig
metadata:
  name: 99-worker-ric-load-sctp-module
  labels:
    machineconfiguration.openshift.io/role: worker-ric
spec:
  config:
    ignition:
      version: 3.1.0
    storage:
      files:
        - path: /etc/modprobe.d/sctp-blacklist.conf
          mode: 0644
          overwrite: true
          contents:
            source: data:,
        - path: /etc/modules-load.d/sctp-load.conf
          mode: 0644
          overwrite: true
          contents:
            source: data:,sctp
EOF
oc create -f /data/install/sctp-module-ric.yaml

# intel ric needs promethus, it needs storage
# you need to craete storage for it
# for testing env in baicell, we create a nfs auto provisor
bash /data/ocp4/ocp4-upi-helpernode-master/files/nfs-provisioner-setup.sh

# intel ric will use the same network method as baicell's ran
# we use host device, it will occupy another nic,
# just for simplify
cat << EOF > /data/install/ric-net.yaml
apiVersion: k8s.cni.cncf.io/v1
kind: NetworkAttachmentDefinition
metadata:
  name: host-device-intel
  namespace: intel
spec:
  config: '{
    "cniVersion": "0.3.0",
    "type": "host-device",
    "device": "eno1",
    "ipam": {
      "type": "host-local",
      "subnet": "192.168.12.0/24",
      "rangeStart": "192.168.12.167",
      "rangeEnd": "192.168.12.167",
      "routes": [{
        "dst": "0.0.0.0/0"
      }],
      "gateway": "192.168.12.1"
    }
  }'
EOF
oc craete -f /data/install/ric-net.yaml

# then, you need to install ric soft from intel
# call intel guy to install it for you
# because the ric soft is under active development
# the install method change from time to time
# currently, it use helm to install
```

# trouble shooting
```bash
# the most important, kernel.sched_rt_runtime_us should be -1, it is setting for realtime, and for stalld
sysctl kernel.sched_rt_runtime_us

sysctl -w kernel.sched_rt_runtime_us=-1

ps -e -o uid,pid,ppid,cls,rtprio,pri,ni,cmd | grep 'stalld\|rcuc\|softirq\|worker\|bin_read\|dumgr\|duoam' 

oc adm must-gather \
--image=registry.redhat.io/openshift4/performance-addon-operator-must-gather-rhel8 

oc get performanceprofile wzh-performanceprofile -o yaml > wzh-performanceprofile.output.yaml

oc describe node/worker-0 > node.worker-0.output

oc describe mcp/worker-rt > mcp.worker-rt.output

# if host device can't release ip address
cd /var/lib/cni/networks/host-device-du
rm -f 192.168.12.105

```

# profile creator

https://docs.openshift.com/container-platform/4.8/scalability_and_performance/cnf-create-performance-profiles.html#cnf-about-the-profile-creator-tool_cnf-create-performance-profiles

```bash

oc adm must-gather --image=quay.io/openshift-kni/performance-addon-operator-must-gather:4.6-snapshot --dest-dir=must-gather

oc adm must-gather --image=quay.io/openshift-kni/performance-addon-operator-must-gather:4.8-snapshot --dest-dir=must-gather

mkdir -p /etc/containers/registries.conf.d

cp -f /data/ocp4/image.registries.conf /etc/containers/registries.conf.d/

podman run --entrypoint performance-profile-creator quay.io/openshift-kni/performance-addon-operator:4.8-snapshot -h

podman run --entrypoint performance-profile-creator -v /data/tmp/must-gather:/must-gather:z quay.io/openshift-kni/performance-addon-operator:4.8-snapshot --mcp-name=worker-rt --reserved-cpu-count=2 --topology-manager-policy=single-numa-node --rt-kernel=true --profile-name=wzh-performanceprofile --power-consumption-mode=ultra-low-latency --disable-ht=true  --must-gather-dir-path /must-gather > my-performance-profile.yaml

```

# baicell vdu container image build

```bash
cd /data/tmp

cat << 'EOF' > init.sh
#!/bin/bash

DU_PATH="/home/BaiBBU_SXSS/"
DRIVER_PATH="/home/bin/nr5g_img/rec/"
L1_PATH="/home/bin/nr5g_img/L1/"

# unset LD_LIBRARY_PATH
export LD_LIBRARY_PATH=/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64_lin/:/opt/intel/compilers_and_libraries_2018.1.176/linux/ipp/lib/intel64_lin/:/opt/intel/compilers_and_libraries_2018.1.163/linux/compiler/lib/intel64_lin/${LD_LIBRARY_PATH:+:$LD_LIBRARY_PATH}


cd $DRIVER_PATH
./install.sh
sleep 5
cd $L1_PATH
./l1.sh -rsub6 &
sleep  30
cd $DU_PATH
./gNB_app start &

sleep infinity
EOF

cat << EOF > Dockerfile
FROM registry.ocp4.redhat.ren:5443/ocp4/du:v1-wzh-shell

RUN mkdir /data
COPY l1.sh /home/bin/nr5g_img/L1/l1.sh
RUN chmod +x /home/bin/nr5g_img/L1/l1.sh
COPY init.sh /data/init.sh
RUN chmod +x /data/init.sh

ENTRYPOINT "/data/init.sh"

EOF

buildah bud --squash -t registry.ocp4.redhat.ren:5443/ocp4/du:v1-wzh-shell-05 -f ./Dockerfile ./

buildah push registry.ocp4.redhat.ren:5443/ocp4/du:v1-wzh-shell-05


oc create -f /data/5gtest/flexran-hostdev-baicells.yaml

oc delete -f /data/5gtest/flexran-hostdev-baicells.yaml

oc create -f /home/wzh/k8s-conf/v-ran/cyclictestpod.wzh.yaml

oc delete -f /home/wzh/k8s-conf/v-ran/cyclictestpod.wzh.yaml

# check which cpu running on.
taskset -pc $$


```

## build from base image
```bash
podman run -it registry.ocp4.redhat.ren:5443/ocp4/du:v1-wzh bash

podman ps -a

buildah commit --squash d92b57138339 registry.ocp4.redhat.ren:5443/ocp4/du:v1-wzh

podman image push registry.ocp4.redhat.ren:5443/ocp4/du:v1-wzh

```

## remove worker-0
```bash
oc delete node worker-0


```

# DIY & check what is going on

!!!! Do not use DIY

```bash
cat << EOF > /data/install/05-worker-kernelarg-realtime.yaml
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfig
metadata:
  labels:
    machineconfiguration.openshift.io/role: worker-rt
  name: 05-worker-kernelarg-realtime
spec:
  config:
    ignition:
      version: 3.1.0
  kernelArguments:
    - no_timer_check  # 禁止运行内核中时钟IRQ源缺陷检测代码。主要用于解决某些AMD平台的CPU占用过高以及时钟过快的故障。
    - clocksource=tsc # clocksource={jiffies|acpi_pm|hpet|tsc} tsc TSC(Time Stamp Counter)的主体是位于CPU里面的一个64位TSC寄存器，与传统的以中断形式存在的周期性时钟不同，TSC是以计数器形式存在的单步递增性时钟，两者的区别在于，周期性时钟是通过周期性触发中断达到计时目的，如心跳一般。而单步递增时钟则不发送中断，取而代之的是由软件自己在需要的时候去主动读取TSC寄存器的值来获得时间。TSC的精度更高并且速度更快，但仅能在较新的CPU(Sandy Bridge之后)上使用。
    - tsc=perfect
    - intel_pstate=disable  # intel_pstate驱动支持现代Intel处理器的温控。 intel_pstate=disable选项可以强制使用传统遗留的CPU驱动acpi_cpufreq
    - selinux=0
    - enforcing=0
    - nmi_watchdog=0  # 配置nmi_watchdog(不可屏蔽中断看门狗) 0 表示关闭看门狗；
    - softlockup_panic=0  # 是否在检测到软死锁(soft-lockup)的时候让内核panic
    - isolcpus=2-19 # 将列表中的CPU从内核SMP平衡和调度算法中剔除。 提出后并不是绝对不能再使用该CPU的，操作系统仍然可以强制指定特定的进程使用哪个CPU(可以通过taskset来做到)。该参数的目的主要是用于实现特定cpu只运行特定进程的目的。
    - nohz_full=2-19  #在 16 核的系统中，设定 nohz_full=1-15 可以在 1 到 15 内核中启用动态无时钟内核性能，并将所有的计时移动至唯一未设定的内核中（0 内核）, [注意](1)"boot CPU"(通常都是"0"号CPU)会无条件的从列表中剔除。(2)这里列出的CPU编号必须也要同时列进"rcu_nocbs=..."参数中。
    - idle=poll # 对CPU进入休眠状态的额外设置。poll 从根本上禁用休眠功能(也就是禁止进入C-states状态)，可以略微提升一些CPU性能，但是却需要多消耗许多电力，得不偿失。不推荐使用。
    - default_hugepagesz=1G
    - hugepagesz=1G
    - hugepages=32
    - skew_tick=1 # Offset the periodic timer tick per cpu to mitigate xtime_lock contention on larger systems, and/or RCU lock contention on all systems with CONFIG_MAXSMP set. Note: increases power consumption, thus should only be enabled if running jitter sensitive (HPC/RT) workloads.
    - rcu_nocbs=2-19  # 指定哪些CPU是No-CB CPU
    - kthread_cpus=0-1
    - irqaffinity=0-1 # 通过内核参数irqaffinity==[cpu列表],设置linux中断的亲和性，设置后，默认由这些cpu核来处理非CPU绑定中断。避免linux中断影响cpu2、cpu3上的实时应用，将linux中断指定到cpu0、cpu1处理。
    - rcu_nocb_poll # 减少了需要从卸载cpu执行唤醒操作。避免了rcuo kthreads线程显式的唤醒。另一方面这会增加耗电量
    - iommu=pt
    - intel_iommu=on
    # profile creator
    - audit=0
    - idle=poll
    - intel_idle.max_cstate=0
    - mce=off
    - nmi_watchdog=0
    - nosmt
    - processor.max_cstate=1
  kernelType: realtime
EOF
oc create -f /data/install/05-worker-kernelarg-realtime.yaml

cat << EOF > /data/install/cpumanager-kubeletconfig.yaml
apiVersion: machineconfiguration.openshift.io/v1
kind: KubeletConfig
metadata:
  name: cpumanager-enabled
spec:
  machineConfigPoolSelector:
    matchLabels:
      machineconfiguration.openshift.io/role: worker-rt
  kubeletConfig:
     cpuManagerPolicy: static 
     cpuManagerReconcilePeriod: 5s 
     topologyManagerPolicy: single-numa-node 
     reservedSystemCPUs: "0,1" 
EOF
oc create -f  /data/install/cpumanager-kubeletconfig.yaml

oc get Tuned/openshift-node-performance-wzh-performanceprofile -o yaml -n openshift-cluster-node-tuning-operator | yq e '.spec.profile[0].data' - | sed  's|^|      |g' | sed '/include=openshift-node,/ s/$/,realtime/'

cat << EOF > /data/install/tuned.yaml
apiVersion: tuned.openshift.io/v1
kind: Tuned
metadata:
  name: wzh-realtime
  namespace: openshift-cluster-node-tuning-operator
spec:
  profile:
  - data: |
`oc get Tuned/openshift-node-performance-wzh-performanceprofile -o yaml -n openshift-cluster-node-tuning-operator | yq e '.spec.profile[0].data' - | sed  's|^|      |g' | sed '/include=openshift-node,/ s/$/,realtime/'`
    name: wzh-realtime
  recommend:
  - machineConfigLabels:
      machineconfiguration.openshift.io/role: worker-rt
    priority: 10
    profile: wzh-realtime
EOF
oc create -f /data/install/tuned.yaml

oc delete -f /data/install/tuned.yaml

crictl logs `crictl ps --name tuned -o json | jq -r .containers[0].id`

crictl exec -it `crictl ps --name tuned -o json | jq -r .containers[0].id` bash

```

```bash
oc get runtimeclass
NAME                                 HANDLER            AGE
performance-wzh-performanceprofile   high-performance   43h

oc get KubeletConfig

oc get Tuned -n openshift-cluster-node-tuning-operator

oc get KubeletConfig/performance-wzh-performanceprofile -o yaml | yq e "del(.metadata.managedFields, .status)" -
```
```yaml
apiVersion: machineconfiguration.openshift.io/v1
kind: KubeletConfig
metadata:
  creationTimestamp: "2021-07-30T07:04:09Z"
  finalizers:
    - 99-worker-rt-generated-kubelet
  generation: 1
  name: performance-wzh-performanceprofile
  ownerReferences:
    - apiVersion: performance.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: PerformanceProfile
      name: wzh-performanceprofile
      uid: 6bfdf08f-3420-4ed2-997d-cfa5922031e6
  resourceVersion: "75507"
  selfLink: /apis/machineconfiguration.openshift.io/v1/kubeletconfigs/performance-wzh-performanceprofile
  uid: 5598e31f-142c-49d7-a29e-8da9b7080f20
spec:
  kubeletConfig:
    apiVersion: kubelet.config.k8s.io/v1beta1
    authentication:
      anonymous: {}
      webhook:
        cacheTTL: 0s
      x509: {}
    authorization:
      webhook:
        cacheAuthorizedTTL: 0s
        cacheUnauthorizedTTL: 0s
    cpuManagerPolicy: static
    cpuManagerReconcilePeriod: 5s
    evictionHard:
      memory.available: 100Mi
    evictionPressureTransitionPeriod: 0s
    fileCheckFrequency: 0s
    httpCheckFrequency: 0s
    imageMinimumGCAge: 0s
    kind: KubeletConfiguration
    kubeReserved:
      cpu: 1000m
      memory: 500Mi
    logging: {}
    memoryManagerPolicy: Static
    nodeStatusReportFrequency: 0s
    nodeStatusUpdateFrequency: 0s
    reservedMemory:
      - limits:
          memory: 1100Mi
        numaNode: 0
    reservedSystemCPUs: 0-1
    runtimeRequestTimeout: 0s
    shutdownGracePeriod: 0s
    shutdownGracePeriodCriticalPods: 0s
    streamingConnectionIdleTimeout: 0s
    syncFrequency: 0s
    systemReserved:
      cpu: 1000m
      memory: 500Mi
    topologyManagerPolicy: single-numa-node
    volumeStatsAggPeriod: 0s
  machineConfigPoolSelector:
    matchLabels:
      machineconfiguration.openshift.io/role: worker-rt

```


```bash
oc get Tuned/openshift-node-performance-wzh-performanceprofile -o yaml -n openshift-cluster-node-tuning-operator | yq e '.spec.profile[0].data' -


[main]
summary=Openshift node optimized for deterministic performance at the cost of increased power consumption, focused on low latency network performance. Based on Tuned 2.11 and Cluster node tuning (oc 4.5)
include=openshift-node,cpu-partitioning

# Inheritance of base profiles legend:
# cpu-partitioning -> network-latency -> latency-performance
# https://github.com/redhat-performance/tuned/blob/master/profiles/latency-performance/tuned.conf
# https://github.com/redhat-performance/tuned/blob/master/profiles/network-latency/tuned.conf
# https://github.com/redhat-performance/tuned/blob/master/profiles/cpu-partitioning/tuned.conf

# All values are mapped with a comment where a parent profile contains them.
# Different values will override the original values in parent profiles.

[variables]
# isolated_cores take a list of ranges; e.g. isolated_cores=2,4-7

isolated_cores=2-19


not_isolated_cores_expanded=${f:cpulist_invert:${isolated_cores_expanded}}

[cpu]
force_latency=cstate.id:1|3                   #  latency-performance  (override)
governor=performance                          #  latency-performance
energy_perf_bias=performance                  #  latency-performance
min_perf_pct=100                              #  latency-performance

[service]
service.stalld=start,enable

[vm]
transparent_hugepages=never                   #  network-latency



[scheduler]
runtime=0
group.ksoftirqd=0:f:11:*:ksoftirqd.*
group.rcuc=0:f:11:*:rcuc.*


[sysctl]
kernel.hung_task_timeout_secs = 600           # cpu-partitioning #realtime
kernel.nmi_watchdog = 0                       # cpu-partitioning #realtime
kernel.sched_rt_runtime_us = -1               # realtime
kernel.timer_migration = 0                    # cpu-partitioning (= 1) #realtime (= 0)
kernel.numa_balancing=0                       # network-latency
net.core.busy_read=50                         # network-latency
net.core.busy_poll=50                         # network-latency
net.ipv4.tcp_fastopen=3                       # network-latency
vm.stat_interval = 10                         # cpu-partitioning  #realtime

# ktune sysctl settings for rhel6 servers, maximizing i/o throughput
#
# Minimal preemption granularity for CPU-bound tasks:
# (default: 1 msec#  (1 + ilog(ncpus)), units: nanoseconds)
kernel.sched_min_granularity_ns=10000000      # latency-performance

# If a workload mostly uses anonymous memory and it hits this limit, the entire
# working set is buffered for I/O, and any more write buffering would require
# swapping, so it's time to throttle writes until I/O can catch up.  Workloads
# that mostly use file mappings may be able to use even higher values.
#
# The generator of dirty data starts writeback at this percentage (system default
# is 20%)
vm.dirty_ratio=10                             # latency-performance

# Start background writeback (via writeback threads) at this percentage (system
# default is 10%)
vm.dirty_background_ratio=3                   # latency-performance

# The swappiness parameter controls the tendency of the kernel to move
# processes out of physical memory and onto the swap disk.
# 0 tells the kernel to avoid swapping processes out of physical memory
# for as long as possible
# 100 tells the kernel to aggressively swap processes out of physical memory
# and move them to swap cache
vm.swappiness=10                              # latency-performance

# The total time the scheduler will consider a migrated process
# "cache hot" and thus less likely to be re-migrated
# (system default is 500000, i.e. 0.5 ms)
kernel.sched_migration_cost_ns=5000000        # latency-performance

[selinux]
avc_cache_threshold=8192                      # Custom (atomic host)


[net]
nf_conntrack_hashsize=131072


[bootloader]
# set empty values to disable RHEL initrd setting in cpu-partitioning
initrd_remove_dir=
initrd_dst_img=
initrd_add_dir=
# overrides cpu-partitioning cmdline
cmdline_cpu_part=+nohz=on rcu_nocbs=${isolated_cores} tuned.non_isolcpus=${not_isolated_cpumask} intel_pstate=disable nosoftlockup

cmdline_realtime=+tsc=nowatchdog intel_iommu=on iommu=pt isolcpus=managed_irq,${isolated_cores} systemd.cpu_affinity=${not_isolated_cores_expanded}

cmdline_hugepages=+
cmdline_additionalArg=+ no_timer_check clocksource=tsc tsc=perfect selinux=0 enforcing=0 nmi_watchdog=0 softlockup_panic=0 isolcpus=2-19 nohz_full=2-19 idle=poll default_hugepagesz=1G hugepagesz=1G hugepages=16 skew_tick=1 rcu_nocbs=2-19 kthread_cpus=0-1 irqaffinity=0-1 rcu_nocb_poll iommu=pt intel_iommu=on audit=0 idle=poll intel_idle.max_cstate=0 mce=off nmi_watchdog=0 nosmt processor.max_cstate=1




```


```bash
[ 1089.301838] stalld: ksoftirqd/11-112 starved on CPU 11 for 672 seconds
[ 1089.313775] stalld: boost_with_deadline failed to boost pid 112: Operation not permitted
[ 1089.327599] stalld: kworker/11:1-253 starved on CPU 11 for 666 seconds
[ 1089.339210] stalld: boost_with_deadline failed to boost pid 253: Operation not permitted
[ 1090.356234] stalld: ksoftirqd/11-112 starved on CPU 11 for 673 seconds
[ 1090.367902] stalld: boost_with_deadline failed to boost pid 112: Operation not permitted
[ 1090.381737] stalld: kworker/11:1-253 starved on CPU 11 for 667 seconds
[ 1090.393352] stalld: boost_with_deadline failed to boost pid 253: Operation not permitted
[ 1091.410439] stalld: ksoftirqd/11-112 starved on CPU 11 for 674 seconds
[ 1091.422614] stalld: boost_with_deadline failed to boost pid 112: Operation not permitted
[ 1091.436161] stalld: kworker/11:1-253 starved on CPU 11 for 668 seconds
[ 1091.447786] stalld: boost_with_deadline failed to boost pid 253: Operation not permitted
[ 1092.464859] stalld: ksoftirqd/11-112 starved on CPU 11 for 675 seconds
[ 1092.477063] stalld: boost_with_deadline failed to boost pid 112: Operation not permitted
[ 1092.490310] stalld: kworker/11:1-253 starved on CPU 11 for 669 seconds
[ 1092.501919] stalld: boost_with_deadline failed to boost pid 253: Operation not permitted
[ 1093.519044] stalld: ksoftirqd/11-112 starved on CPU 11 for 676 seconds
[ 1093.530693] stalld: boost_with_deadline failed to boost pid 112: Operation not permitted
[ 1093.544536] stalld: kworker/11:1-253 starved on CPU 11 for 670 seconds
[ 1093.556172] stalld: boost_with_deadline failed to boost pid 253: Operation not permitted
[ 1094.573213] stalld: ksoftirqd/11-112 starved on CPU 11 for 677 seconds
[ 1094.585859] stalld: boost_with_deadline failed to boost pid 112: Operation not permitted
[ 1094.599127] stalld: kworker/11:1-253 starved on CPU 11 for 671 seconds
[ 1094.610777] stalld: boost_with_deadline failed to boost pid 253: Operation not permitted




ps -e -o uid,pid,ppid,cls,rtprio,pri,ni,cmd | grep 'stalld\|rcuc\|softirq\|worker\|bin_read\|dumgr\|duoam'


    0       6       2  TS      -  39 -20 [kworker/0:0H]
    0       8       2  TS      -  19   0 [kworker/u40:0-events_unbound]
    0      10       2  FF     11  51   - [ksoftirqd/0]
    0      13       2  FF     11  51   - [rcuc/0]
    0      22       2  FF     11  51   - [rcuc/1]
    0      23       2  FF     11  51   - [ksoftirqd/1]
    0      25       2  TS      -  39 -20 [kworker/1:0H-kblockd]
    0      30       2  FF     11  51   - [rcuc/2]
    0      31       2  FF     11  51   - [ksoftirqd/2]
    0      32       2  TS      -  19   0 [kworker/2:0-mm_percpu_wq]
    0      33       2  TS      -  39 -20 [kworker/2:0H]
    0      39       2  FF     11  51   - [rcuc/3]
    0      40       2  FF     11  51   - [ksoftirqd/3]
    0      41       2  TS      -  19   0 [kworker/3:0-mm_percpu_wq]
    0      42       2  TS      -  39 -20 [kworker/3:0H]
    0      48       2  FF     11  51   - [rcuc/4]
    0      49       2  FF     11  51   - [ksoftirqd/4]
    0      50       2  TS      -  19   0 [kworker/4:0-mm_percpu_wq]
    0      51       2  TS      -  39 -20 [kworker/4:0H]
    0      57       2  FF     11  51   - [rcuc/5]
    0      58       2  FF     11  51   - [ksoftirqd/5]
    0      59       2  TS      -  19   0 [kworker/5:0-mm_percpu_wq]
    0      60       2  TS      -  39 -20 [kworker/5:0H]
    0      66       2  FF     11  51   - [rcuc/6]
    0      67       2  FF     11  51   - [ksoftirqd/6]
    0      68       2  TS      -  19   0 [kworker/6:0-mm_percpu_wq]
    0      69       2  TS      -  39 -20 [kworker/6:0H]
    0      75       2  FF     11  51   - [rcuc/7]
    0      76       2  FF     11  51   - [ksoftirqd/7]
    0      77       2  TS      -  19   0 [kworker/7:0-mm_percpu_wq]
    0      78       2  TS      -  39 -20 [kworker/7:0H]
    0      84       2  FF     11  51   - [rcuc/8]
    0      85       2  FF     11  51   - [ksoftirqd/8]
    0      86       2  TS      -  19   0 [kworker/8:0-mm_percpu_wq]
    0      87       2  TS      -  39 -20 [kworker/8:0H]
    0      93       2  FF     11  51   - [rcuc/9]
    0      94       2  FF     11  51   - [ksoftirqd/9]
    0      95       2  TS      -  19   0 [kworker/9:0-mm_percpu_wq]
    0      96       2  TS      -  39 -20 [kworker/9:0H]
    0     102       2  FF     11  51   - [rcuc/10]
    0     103       2  FF     11  51   - [ksoftirqd/10]
    0     104       2  TS      -  19   0 [kworker/10:0-mm_percpu_wq]
    0     105       2  TS      -  39 -20 [kworker/10:0H]
    0     111       2  FF     11  51   - [rcuc/11]
    0     112       2  FF     11  51   - [ksoftirqd/11]
    0     113       2  TS      -  19   0 [kworker/11:0-mm_percpu_wq]
    0     114       2  TS      -  39 -20 [kworker/11:0H]
    0     121       2  FF     11  51   - [rcuc/12]
    0     122       2  FF     11  51   - [ksoftirqd/12]
    0     123       2  TS      -  19   0 [kworker/12:0-mm_percpu_wq]
    0     124       2  TS      -  39 -20 [kworker/12:0H]
    0     130       2  FF     11  51   - [rcuc/13]
    0     131       2  FF     11  51   - [ksoftirqd/13]
    0     132       2  TS      -  19   0 [kworker/13:0-mm_percpu_wq]
    0     133       2  TS      -  39 -20 [kworker/13:0H]
    0     139       2  FF     11  51   - [rcuc/14]
    0     140       2  FF     11  51   - [ksoftirqd/14]
    0     141       2  TS      -  19   0 [kworker/14:0-mm_percpu_wq]
    0     142       2  TS      -  39 -20 [kworker/14:0H]
    0     148       2  FF     11  51   - [rcuc/15]
    0     149       2  FF     11  51   - [ksoftirqd/15]
    0     150       2  TS      -  19   0 [kworker/15:0-mm_percpu_wq]
    0     151       2  TS      -  39 -20 [kworker/15:0H]
    0     157       2  FF     11  51   - [rcuc/16]
    0     158       2  FF     11  51   - [ksoftirqd/16]
    0     159       2  TS      -  19   0 [kworker/16:0-mm_percpu_wq]
    0     160       2  TS      -  39 -20 [kworker/16:0H]
    0     166       2  FF     11  51   - [rcuc/17]
    0     167       2  FF     11  51   - [ksoftirqd/17]
    0     168       2  TS      -  19   0 [kworker/17:0-mm_percpu_wq]
    0     169       2  TS      -  39 -20 [kworker/17:0H]
    0     175       2  FF     11  51   - [rcuc/18]
    0     176       2  FF     11  51   - [ksoftirqd/18]
    0     177       2  TS      -  19   0 [kworker/18:0-mm_percpu_wq]
    0     178       2  TS      -  39 -20 [kworker/18:0H]
    0     184       2  FF     11  51   - [rcuc/19]
    0     185       2  FF     11  51   - [ksoftirqd/19]
    0     186       2  TS      -  19   0 [kworker/19:0-mm_percpu_wq]
    0     187       2  TS      -  39 -20 [kworker/19:0H]
    0     244       2  TS      -  19   0 [kworker/2:1-mm_percpu_wq]
    0     245       2  TS      -  19   0 [kworker/3:1-mm_percpu_wq]
    0     246       2  TS      -  19   0 [kworker/4:1-mm_percpu_wq]
    0     247       2  TS      -  19   0 [kworker/5:1-mm_percpu_wq]
    0     248       2  TS      -  19   0 [kworker/6:1-mm_percpu_wq]
    0     249       2  TS      -  19   0 [kworker/7:1-mm_percpu_wq]
    0     250       2  TS      -  19   0 [kworker/8:1-mm_percpu_wq]
    0     251       2  TS      -  19   0 [kworker/9:1-mm_percpu_wq]
    0     252       2  TS      -  19   0 [kworker/10:1-mm_percpu_wq]
    0     253       2  TS      -  19   0 [kworker/11:1-mm_percpu_wq]
    0     254       2  TS      -  19   0 [kworker/12:1-mm_percpu_wq]
    0     255       2  TS      -  19   0 [kworker/13:1-mm_percpu_wq]
    0     256       2  TS      -  19   0 [kworker/14:1-mm_percpu_wq]
    0     257       2  TS      -  19   0 [kworker/15:1-mm_percpu_wq]
    0     258       2  TS      -  19   0 [kworker/16:1-mm_percpu_wq]
    0     259       2  TS      -  19   0 [kworker/17:1-mm_percpu_wq]
    0     260       2  TS      -  19   0 [kworker/18:1-mm_percpu_wq]
    0     261       2  TS      -  19   0 [kworker/19:1-mm_percpu_wq]
    0     813       2  TS      -  19   0 [kworker/u40:7-events_unbound]
    0     850       2  TS      -  39 -20 [kworker/1:1H-kblockd]
    0    1180       2  TS      -  39 -20 [kworker/u41:0]
    0    2099       1  TS      -  19   0 kubelet --config=/etc/kubernetes/kubelet.conf --bootstrap-kubeconfig=/etc/kubernetes/kubeconfig --kubeconfig=/var/lib/kubelet/kubeconfig --container-runtime=remote --container-runtime-endpoint=/var/run/crio/crio.sock --runtime-cgroups=/system.slice/crio.service --node-labels=node-role.kubernetes.io/worker,node.openshift.io/os_id=rhcos --node-ip=192.168.7.16 --minimum-container-ttl-duration=6m0s --volume-plugin-dir=/etc/kubernetes/kubelet-plugins/volume/exec --cloud-provider= --pod-infra-container-image=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:aa6410430d05d37ac258c34c2279653595ea82dcaabab5ad1bd5c1eb8db14c39 --v=3
    0    2683    2655  TS      -  19   0 /usr/bin/openshift-sdn-node --node-name worker-0 --node-ip 192.168.7.16 --proxy-config /config/kube-proxy-config.yaml --v 2
    0    3953    3934  TS      -  19   0 /usr/bin/network-metrics --node-name worker-0
    0    4728       1  FF     10  50   - /usr/local/bin/stalld -p 1000000000 -r 10000 -d 3 -t 20 --log_syslog --log_kmsg --foreground --pidfile /run/stalld.pid
    0   14036   12919  TS      -  19   0 ./duoam ../cfg/Proprietary_gNodeB_DU_Data_Model.xml ../cfg/TR196_gNodeB_DU_Data_Model.xml
    0   14038   14036  TS      -  19   0 dumgr --dumgr_ip 192.168.12.105 --dumgr_port 2236 --duoam_ip 192.168.12.105 --duoam_port 2235 --shared_core_bitmap 28
    0   14039   14036  TS      -  19   0 gnb_du_layer2 --mac_ip=192.168.12.105 --mac_port=2336 --duoam_ip=192.168.12.105 --duoam_port=2235 --rlc_ip=192.168.12.105 --rlc_port=2436 --duf1u_ip=192.168.12.105 --duf1u_port=2536 --dumgr_ip=192.168.12.105 --dumgr_port=2236 --bin_reader_core=2 --log_num_files=20 --hp_core_num=5 --rlc_master_core_num=6 --shared_core_bitmap=28 --recvr_thread_core_num=9 --shm_size=50
    0   14040   14039  FF     80 120   - bin_reader --shm_name=MAC_REGION --shm_size=50 --log_file_name=MAC_REGION --logger_option=binary --log_file_size=52428800 --bin_name=gnb_du_layer2 --log_num_files=20 --core_num=2
    0   14144   14039  FF     80 120   - bin_reader --shm_name=RLC_TIMER_REGION_T0_ --shm_size=50 --log_file_name=RLC_TIMER_REGION_T0_ --logger_option=binary --log_file_size=52428800 --bin_name=gnb_du_layer2 --log_num_files=20 --core_num=2
    0   14146   14039  FF     80 120   - bin_reader --shm_name=RLC_ACCUMULATOR_REGION --shm_size=50 --log_file_name=RLC_ACCUMULATOR_REGION --logger_option=binary --log_file_size=52428800 --bin_name=gnb_du_layer2 --log_num_files=20 --core_num=2
    0   14148   14039  FF     80 120   - bin_reader --shm_name=PR_DU_REGION --shm_size=50 --log_file_name=PR_DU_REGION --logger_option=binary --log_file_size=52428800 --bin_name=gnb_du_layer2 --log_num_files=20 --core_num=2
    0   14149   14039  FF     80 120   - bin_reader --shm_name=RLC_MASTER_REGION --shm_size=50 --log_file_name=RLC_MASTER_REGION --logger_option=binary --log_file_size=52428800 --bin_name=gnb_du_layer2 --log_num_files=20 --core_num=2
    0   14169   14039  FF     80 120   - bin_reader --shm_name=F1_DU_WORKER_REGION_T0_ --shm_size=50 --log_file_name=F1_DU_WORKER_REGION_T0_ --logger_option=binary --log_file_size=52428800 --bin_name=gnb_du_layer2 --log_num_files=20 --core_num=2
    0   14171   14039  FF     80 120   - bin_reader --shm_name=RECEIVER_DU_REGION_T0_ --shm_size=50 --log_file_name=RECEIVER_DU_REGION_T0_ --logger_option=binary --log_file_size=52428800 --bin_name=gnb_du_layer2 --log_num_files=20 --core_num=2
    0   14174   14039  FF     80 120   - bin_reader --shm_name=RLC_WORKER_REGION_T0_ --shm_size=50 --log_file_name=RLC_WORKER_REGION_T0_ --logger_option=binary --log_file_size=52428800 --bin_name=gnb_du_layer2 --log_num_files=20 --core_num=2
    0   14196   14039  FF     80 120   - bin_reader --shm_name=MAC_SLOT_HDLR_THD_REGION_T0_ --shm_size=50 --log_file_name=MAC_SLOT_HDLR_THD_REGION_T0_ --logger_option=binary --log_file_size=52428800 --bin_name=gnb_du_layer2 --log_num_files=20 --core_num=2
    0   14198   14039  FF     80 120   - bin_reader --shm_name=MAC_TX_CTRL_DATA_THD_REGION_T0_ --shm_size=50 --log_file_name=MAC_TX_CTRL_DATA_THD_REGION_T0_ --logger_option=binary --log_file_size=52428800 --bin_name=gnb_du_layer2 --log_num_files=20 --core_num=2
    0   14200   14039  FF     80 120   - bin_reader --shm_name=MAC_LP_THD_REGION_T0_ --shm_size=50 --log_file_name=MAC_LP_THD_REGION_T0_ --logger_option=binary --log_file_size=52428800 --bin_name=gnb_du_layer2 --log_num_files=20 --core_num=2
    0   14562   14039  FF     80 120   - bin_reader --shm_name=MAC_SLOT_HDLR_THD_REGION_T1_ --shm_size=50 --log_file_name=MAC_SLOT_HDLR_THD_REGION_T1_ --logger_option=binary --log_file_size=52428800 --bin_name=gnb_du_layer2 --log_num_files=20 --core_num=2
    0   14564   14039  FF     80 120   - bin_reader --shm_name=MAC_TX_CTRL_DATA_THD_REGION_T1_ --shm_size=50 --log_file_name=MAC_TX_CTRL_DATA_THD_REGION_T1_ --logger_option=binary --log_file_size=52428800 --bin_name=gnb_du_layer2 --log_num_files=20 --core_num=2
    0   14566   14039  FF     80 120   - bin_reader --shm_name=MAC_LP_THD_REGION_T1_ --shm_size=50 --log_file_name=MAC_LP_THD_REGION_T1_ --logger_option=binary --log_file_size=52428800 --bin_name=gnb_du_layer2 --log_num_files=20 --core_num=2
    0   14709   14039  FF     80 120   - bin_reader --shm_name=MAC_SLOT_HDLR_THD_REGION_T2_ --shm_size=50 --log_file_name=MAC_SLOT_HDLR_THD_REGION_T2_ --logger_option=binary --log_file_size=52428800 --bin_name=gnb_du_layer2 --log_num_files=20 --core_num=2
    0   14711   14039  FF     80 120   - bin_reader --shm_name=MAC_TX_CTRL_DATA_THD_REGION_T2_ --shm_size=50 --log_file_name=MAC_TX_CTRL_DATA_THD_REGION_T2_ --logger_option=binary --log_file_size=52428800 --bin_name=gnb_du_layer2 --log_num_files=20 --core_num=2
    0   14723   14039  FF     80 120   - bin_reader --shm_name=MAC_LP_THD_REGION_T2_ --shm_size=50 --log_file_name=MAC_LP_THD_REGION_T2_ --logger_option=binary --log_file_size=52428800 --bin_name=gnb_du_layer2 --log_num_files=20 --core_num=2
    0   14872   14039  FF     80 120   - bin_reader --shm_name=MAC_SLOT_HDLR_THD_REGION_T3_ --shm_size=50 --log_file_name=MAC_SLOT_HDLR_THD_REGION_T3_ --logger_option=binary --log_file_size=52428800 --bin_name=gnb_du_layer2 --log_num_files=20 --core_num=2
    0   14874   14039  FF     80 120   - bin_reader --shm_name=MAC_TX_CTRL_DATA_THD_REGION_T3_ --shm_size=50 --log_file_name=MAC_TX_CTRL_DATA_THD_REGION_T3_ --logger_option=binary --log_file_size=52428800 --bin_name=gnb_du_layer2 --log_num_files=20 --core_num=2
    0   14876   14039  FF     80 120   - bin_reader --shm_name=MAC_LP_THD_REGION_T3_ --shm_size=50 --log_file_name=MAC_LP_THD_REGION_T3_ --logger_option=binary --log_file_size=52428800 --bin_name=gnb_du_layer2 --log_num_files=20 --core_num=2
    0   20627       2  TS      -  19   0 [kworker/0:1-events_power_efficient]
    0   32565       2  TS      -  19   0 [kworker/u40:1-events_unbound]
    0   56215       2  TS      -  19   0 [kworker/1:1-cgroup_pidlist_destroy]
    0   65381       2  TS      -  19   0 [kworker/1:0-xfs-cil/dm-0]
    0   66247       2  TS      -  39 -20 [kworker/0:2H-kblockd]
    0   69121       2  TS      -  19   0 [kworker/u40:2-events_unbound]
    0   70399       2  TS      -  19   0 [kworker/0:0-events]
    0   74568       2  TS      -  19   0 [kworker/1:2-cgroup_pidlist_destroy]
    0   79426       2  TS      -  19   0 [kworker/0:2-events]
    0   83723    4863  TS      -  19   0 grep --color=auto stalld\|rcuc\|softirq\|worker\|bin_read\|dumgr\|duoam



ls /proc | egrep '^[0-9]+$' | xargs -I DEMO echo "if [[ -f /proc/DEMO/status ]]; then grep -s -i name /proc/DEMO/status | tr -d '\n'; echo -n -e '\t'; grep -s -i cpus_allowed_list /proc/DEMO/status ; fi " | sh | column -t -s $'\t'
# Name:  systemd                       Cpus_allowed_list:  0-1
# Name:  ksoftirqd/0                   Cpus_allowed_list:  0
# Name:  watchdog/11                   Cpus_allowed_list:  0-19
# Name:  xfsalloc                      Cpus_allowed_list:  0-19
# Name:  xfs_mru_cache                 Cpus_allowed_list:  0-19
# Name:  xfs-buf/sda4                  Cpus_allowed_list:  0-19
# Name:  xfs-conv/sda4                 Cpus_allowed_list:  0
# Name:  xfs-cil/sda4                  Cpus_allowed_list:  0-19
# Name:  xfs-reclaim/sda               Cpus_allowed_list:  0-19
# Name:  migration/11                  Cpus_allowed_list:  11
# Name:  xfs-eofblocks/s               Cpus_allowed_list:  0-19
# Name:  xfs-log/sda4                  Cpus_allowed_list:  0-19
# Name:  xfsaild/sda4                  Cpus_allowed_list:  0-1
# Name:  rcuc/11                       Cpus_allowed_list:  11
# Name:  ksoftirqd/11                  Cpus_allowed_list:  11
# Name:  kworker/11:0-mm_percpu_wq     Cpus_allowed_list:  11
# Name:  conmon                        Cpus_allowed_list:  0-1
# Name:  kworker/11:0H                 Cpus_allowed_list:  11
# Name:  bash                          Cpus_allowed_list:  0-19
# Name:  rcub/2                        Cpus_allowed_list:  0-1
# Name:  rcuop/11                      Cpus_allowed_list:  0-1
# Name:  sleep                         Cpus_allowed_list:  0-19
# Name:  cpuhp/12                      Cpus_allowed_list:  12
# Name:  watchdog/12                   Cpus_allowed_list:  0-19
# Name:  rcu_preempt                   Cpus_allowed_list:  0-1
# Name:  migration/12                  Cpus_allowed_list:  12
# Name:  rcuc/12                       Cpus_allowed_list:  12
# Name:  ksoftirqd/12                  Cpus_allowed_list:  12
# Name:  kworker/12:0-mm_percpu_wq     Cpus_allowed_list:  12
# Name:  kworker/12:0H                 Cpus_allowed_list:  12
# Name:  rcuop/12                      Cpus_allowed_list:  0-1
# Name:  cpuhp/13                      Cpus_allowed_list:  13
# Name:  watchdog/13                   Cpus_allowed_list:  0-19
# Name:  systemd-journal               Cpus_allowed_list:  0-1
# Name:  migration/13                  Cpus_allowed_list:  13
# Name:  rcuc/13                       Cpus_allowed_list:  13
# Name:  systemd-udevd                 Cpus_allowed_list:  0-1
# Name:  rcub/1                        Cpus_allowed_list:  0-1
# Name:  ksoftirqd/13                  Cpus_allowed_list:  13
# Name:  kworker/13:0-mm_percpu_wq     Cpus_allowed_list:  13
# Name:  irq/167-ioat-ms               Cpus_allowed_list:  0
# Name:  irq/169-ioat-ms               Cpus_allowed_list:  1
# Name:  kworker/13:0H                 Cpus_allowed_list:  13
# Name:  irq/170-ioat-ms               Cpus_allowed_list:  0
# Name:  kipmi0                        Cpus_allowed_list:  0-1
# Name:  irq/171-ioat-ms               Cpus_allowed_list:  1
# Name:  irq/172-ioat-ms               Cpus_allowed_list:  0
# Name:  irq/173-ioat-ms               Cpus_allowed_list:  1
# Name:  irq/174-ioat-ms               Cpus_allowed_list:  0
# Name:  irq/175-ioat-ms               Cpus_allowed_list:  1
# Name:  rcuop/13                      Cpus_allowed_list:  0-1
# Name:  irq/16-i801_smb               Cpus_allowed_list:  0
# Name:  cpuhp/14                      Cpus_allowed_list:  14
# Name:  rdma-ndd                      Cpus_allowed_list:  0-1
# Name:  rpciod                        Cpus_allowed_list:  0-19
# Name:  xprtiod                       Cpus_allowed_list:  0-19
# Name:  ttm_swap                      Cpus_allowed_list:  0-19
# Name:  watchdog/14                   Cpus_allowed_list:  0-19
# Name:  nfit                          Cpus_allowed_list:  0-19
# Name:  migration/14                  Cpus_allowed_list:  14
# Name:  rcuc/14                       Cpus_allowed_list:  14
# Name:  ksoftirqd/14                  Cpus_allowed_list:  14
# Name:  kworker/14:0-mm_percpu_wq     Cpus_allowed_list:  14
# Name:  rcuc/0                        Cpus_allowed_list:  0
# Name:  kworker/14:0H                 Cpus_allowed_list:  14
# Name:  kworker/0:25-events           Cpus_allowed_list:  0
# Name:  rcuop/14                      Cpus_allowed_list:  0-1
# Name:  jbd2/sda3-8                   Cpus_allowed_list:  0-1
# Name:  cpuhp/15                      Cpus_allowed_list:  15
# Name:  ext4-rsv-conver               Cpus_allowed_list:  0-19
# Name:  watchdog/15                   Cpus_allowed_list:  0-19
# Name:  migration/15                  Cpus_allowed_list:  15
# Name:  rcuc/15                       Cpus_allowed_list:  15
# Name:  ksoftirqd/15                  Cpus_allowed_list:  15
# Name:  kworker/15:0-mm_percpu_wq     Cpus_allowed_list:  15
# Name:  sssd                          Cpus_allowed_list:  0-1
# Name:  kworker/15:0H                 Cpus_allowed_list:  15
# Name:  kworker/0:1-events            Cpus_allowed_list:  0
# Name:  rcuog/15                      Cpus_allowed_list:  0-1
# Name:  migration/0                   Cpus_allowed_list:  0
# Name:  rcuop/15                      Cpus_allowed_list:  0-1
# Name:  cpuhp/16                      Cpus_allowed_list:  16
# Name:  watchdog/16                   Cpus_allowed_list:  0-19
# Name:  dbus-daemon                   Cpus_allowed_list:  0-1
# Name:  migration/16                  Cpus_allowed_list:  16
# Name:  rcuc/16                       Cpus_allowed_list:  16
# Name:  ksoftirqd/16                  Cpus_allowed_list:  16
# Name:  kworker/16:0-mm_percpu_wq     Cpus_allowed_list:  16
# Name:  chronyd                       Cpus_allowed_list:  0-1
# Name:  kworker/16:0H                 Cpus_allowed_list:  16
# Name:  rcuop/16                      Cpus_allowed_list:  0-1
# Name:  kworker/0:19-events           Cpus_allowed_list:  0
# Name:  cpuhp/17                      Cpus_allowed_list:  17
# Name:  watchdog/0                    Cpus_allowed_list:  0
# Name:  watchdog/17                   Cpus_allowed_list:  0-19
# Name:  migration/17                  Cpus_allowed_list:  17
# Name:  rcuc/17                       Cpus_allowed_list:  17
# Name:  ksoftirqd/17                  Cpus_allowed_list:  17
# Name:  kworker/17:0-mm_percpu_wq     Cpus_allowed_list:  17
# Name:  sssd_be                       Cpus_allowed_list:  0-1
# Name:  kworker/0:21-events           Cpus_allowed_list:  0
# Name:  kworker/17:0H                 Cpus_allowed_list:  17
# Name:  kworker/0:30-events           Cpus_allowed_list:  0
# Name:  kworker/0:35-events           Cpus_allowed_list:  0
# Name:  rcuop/17                      Cpus_allowed_list:  0-1
# Name:  kworker/u40:3-bnxt_pf_wq      Cpus_allowed_list:  0-1
# Name:  cpuhp/18                      Cpus_allowed_list:  18
# Name:  kworker/1:3-events            Cpus_allowed_list:  1
# Name:  kworker/0:4-events            Cpus_allowed_list:  0
# Name:  watchdog/18                   Cpus_allowed_list:  0-19
# Name:  kworker/1:13-events           Cpus_allowed_list:  1
# Name:  agetty                        Cpus_allowed_list:  0-1
# Name:  kworker/0:12-events           Cpus_allowed_list:  0
# Name:  kworker/0:15-events           Cpus_allowed_list:  0
# Name:  kworker/0:17-events           Cpus_allowed_list:  0
# Name:  migration/18                  Cpus_allowed_list:  18
# Name:  kworker/0:20-events           Cpus_allowed_list:  0
# Name:  kworker/0:34-events           Cpus_allowed_list:  0
# Name:  cpuhp/0                       Cpus_allowed_list:  0
# Name:  rcuc/18                       Cpus_allowed_list:  18
# Name:  kworker/0:40-events           Cpus_allowed_list:  0
# Name:  ksoftirqd/18                  Cpus_allowed_list:  18
# Name:  kworker/18:0-mm_percpu_wq     Cpus_allowed_list:  18
# Name:  kworker/0:2-events            Cpus_allowed_list:  0
# Name:  kworker/1:4-events            Cpus_allowed_list:  1
# Name:  kworker/18:0H                 Cpus_allowed_list:  18
# Name:  kworker/1:0-events            Cpus_allowed_list:  1
# Name:  kworker/0:0-events            Cpus_allowed_list:  0
# Name:  kworker/1:1-events            Cpus_allowed_list:  1
# Name:  kworker/0:3-events            Cpus_allowed_list:  0
# Name:  kworker/0:5-events            Cpus_allowed_list:  0
# Name:  kworker/0:6-events            Cpus_allowed_list:  0
# Name:  kworker/u40:2-events_unbound  Cpus_allowed_list:  0-1
# Name:  sshd                          Cpus_allowed_list:  0-1
# Name:  systemd                       Cpus_allowed_list:  0-1
# Name:  (sd-pam)                      Cpus_allowed_list:  0-1
# Name:  sshd                          Cpus_allowed_list:  0-1
# Name:  bash                          Cpus_allowed_list:  0-1
# Name:  sudo                          Cpus_allowed_list:  0-1
# Name:  bash                          Cpus_allowed_list:  0-1
# Name:  kworker/1:2-events            Cpus_allowed_list:  1
# Name:  kworker/1:5-events            Cpus_allowed_list:  1
# Name:  kworker/1:6-events            Cpus_allowed_list:  1
# Name:  kworker/1:7-events            Cpus_allowed_list:  1
# Name:  kworker/1:8-events            Cpus_allowed_list:  1
# Name:  kworker/0:7-events            Cpus_allowed_list:  0
# Name:  kworker/1:9-events            Cpus_allowed_list:  1
# Name:  kworker/1:10-events           Cpus_allowed_list:  1
# Name:  kworker/0:8-events            Cpus_allowed_list:  0
# Name:  rcuop/18                      Cpus_allowed_list:  0-1
# Name:  kworker/0:9-events            Cpus_allowed_list:  0
# Name:  kworker/0:10-events           Cpus_allowed_list:  0
# Name:  kworker/0:11-events           Cpus_allowed_list:  0
# Name:  kworker/0:13-events           Cpus_allowed_list:  0
# Name:  kworker/1:11-events           Cpus_allowed_list:  1
# Name:  kworker/1:12-events           Cpus_allowed_list:  1
# Name:  kworker/1:14-events           Cpus_allowed_list:  1
# Name:  kworker/1:15-events           Cpus_allowed_list:  1
# Name:  kworker/0:14-events           Cpus_allowed_list:  0
# Name:  kworker/1:16-events           Cpus_allowed_list:  1
# Name:  kworker/0:16-events           Cpus_allowed_list:  0
# Name:  cpuhp/19                      Cpus_allowed_list:  19
# Name:  irq/119-i40e-en               Cpus_allowed_list:  0
# Name:  irq/120-i40e-en               Cpus_allowed_list:  1
# Name:  irq/121-i40e-en               Cpus_allowed_list:  0
# Name:  irq/122-i40e-en               Cpus_allowed_list:  1
# Name:  irq/123-i40e-en               Cpus_allowed_list:  0
# Name:  irq/124-i40e-en               Cpus_allowed_list:  1
# Name:  irq/125-i40e-en               Cpus_allowed_list:  0
# Name:  irq/126-i40e-en               Cpus_allowed_list:  1
# Name:  irq/127-i40e-en               Cpus_allowed_list:  0
# Name:  irq/128-i40e-en               Cpus_allowed_list:  1
# Name:  irq/129-i40e-en               Cpus_allowed_list:  0
# Name:  irq/130-i40e-en               Cpus_allowed_list:  1
# Name:  irq/131-i40e-en               Cpus_allowed_list:  0
# Name:  irq/132-i40e-en               Cpus_allowed_list:  1
# Name:  irq/133-i40e-en               Cpus_allowed_list:  0
# Name:  irq/134-i40e-en               Cpus_allowed_list:  0
# Name:  irq/135-i40e-en               Cpus_allowed_list:  0
# Name:  irq/136-i40e-en               Cpus_allowed_list:  0
# Name:  irq/137-i40e-en               Cpus_allowed_list:  0
# Name:  irq/138-i40e-en               Cpus_allowed_list:  0
# Name:  sssd_nss                      Cpus_allowed_list:  0-1
# Name:  kworker/1:17-events           Cpus_allowed_list:  1
# Name:  kworker/u40:0-events_unbound  Cpus_allowed_list:  0-1
# Name:  kworker/0:18-events           Cpus_allowed_list:  0
# Name:  kworker/0:22-events           Cpus_allowed_list:  0
# Name:  kworker/1:18-events           Cpus_allowed_list:  1
# Name:  kworker/1:19-events           Cpus_allowed_list:  1
# Name:  kworker/u40:1-events_unbound  Cpus_allowed_list:  0-1
# Name:  kworker/1:20-events           Cpus_allowed_list:  1
# Name:  kworker/0:23-events           Cpus_allowed_list:  0
# Name:  watchdog/19                   Cpus_allowed_list:  0-19
# Name:  kworker/0:24-events           Cpus_allowed_list:  0
# Name:  kworker/0:26-events           Cpus_allowed_list:  0
# Name:  kworker/1:21-events           Cpus_allowed_list:  1
# Name:  kworker/1:22-events           Cpus_allowed_list:  1
# Name:  kworker/1:23-events           Cpus_allowed_list:  1
# Name:  kworker/0:27-events           Cpus_allowed_list:  0
# Name:  kworker/0:28-events           Cpus_allowed_list:  0
# Name:  migration/19                  Cpus_allowed_list:  19
# Name:  kworker/1:24                  Cpus_allowed_list:  1
# Name:  kworker/1:25                  Cpus_allowed_list:  1
# Name:  sleep                         Cpus_allowed_list:  0-19
# Name:  sleep                         Cpus_allowed_list:  0-19
# Name:  sh                            Cpus_allowed_list:  0-1
# Name:  column                        Cpus_allowed_list:  0-1
# Name:  rcuc/19                       Cpus_allowed_list:  19
# Name:  ksoftirqd/19                  Cpus_allowed_list:  19
# Name:  cpuhp/1                       Cpus_allowed_list:  1
# Name:  kworker/19:0-mm_percpu_wq     Cpus_allowed_list:  19
# Name:  kworker/19:0H                 Cpus_allowed_list:  19
# Name:  rcuop/19                      Cpus_allowed_list:  0-1
# Name:  systemd-logind                Cpus_allowed_list:  0-1
# Name:  watchdog/1                    Cpus_allowed_list:  0-19
# Name:  ovsdb-server                  Cpus_allowed_list:  0-1
# Name:  kdevtmpfs                     Cpus_allowed_list:  0-1
# Name:  netns                         Cpus_allowed_list:  0-19
# Name:  migration/1                   Cpus_allowed_list:  1
# Name:  rcu_tasks_kthre               Cpus_allowed_list:  0-1
# Name:  khungtaskd                    Cpus_allowed_list:  0-1
# Name:  oom_reaper                    Cpus_allowed_list:  0-1
# Name:  writeback                     Cpus_allowed_list:  0-19
# Name:  kcompactd0                    Cpus_allowed_list:  0-1
# Name:  ksmd                          Cpus_allowed_list:  0-1
# Name:  crypto                        Cpus_allowed_list:  0-19
# Name:  kintegrityd                   Cpus_allowed_list:  0-19
# Name:  kblockd                       Cpus_allowed_list:  0-19
# Name:  kthreadd                      Cpus_allowed_list:  0-1
# Name:  rcuc/1                        Cpus_allowed_list:  1
# Name:  blkcg_punt_bio                Cpus_allowed_list:  0-19
# Name:  irq/9-acpi                    Cpus_allowed_list:  0
# Name:  tpm_dev_wq                    Cpus_allowed_list:  0-19
# Name:  md                            Cpus_allowed_list:  0-19
# Name:  edac-poller                   Cpus_allowed_list:  0-19
# Name:  watchdogd                     Cpus_allowed_list:  0-1
# Name:  kworker/1:1H-kblockd          Cpus_allowed_list:  1
# Name:  ksoftirqd/1                   Cpus_allowed_list:  1
# Name:  kswapd0                       Cpus_allowed_list:  0-1
# Name:  kworker/1:0H-events_highpri   Cpus_allowed_list:  1
# Name:  cpuhp/2                       Cpus_allowed_list:  2
# Name:  ovs-vswitchd                  Cpus_allowed_list:  0-1
# Name:  watchdog/2                    Cpus_allowed_list:  0-19
# Name:  NetworkManager                Cpus_allowed_list:  0-1
# Name:  sshd                          Cpus_allowed_list:  0-1
# Name:  agetty                        Cpus_allowed_list:  0-1
# Name:  irq/89-i40e-ens               Cpus_allowed_list:  1
# Name:  irq/90-i40e-ens               Cpus_allowed_list:  1
# Name:  irq/91-i40e-ens               Cpus_allowed_list:  0
# Name:  irq/92-i40e-ens               Cpus_allowed_list:  0
# Name:  irq/93-i40e-ens               Cpus_allowed_list:  1
# Name:  irq/94-i40e-ens               Cpus_allowed_list:  1
# Name:  irq/95-i40e-ens               Cpus_allowed_list:  0
# Name:  irq/96-i40e-ens               Cpus_allowed_list:  0
# Name:  irq/97-i40e-ens               Cpus_allowed_list:  0
# Name:  irq/98-i40e-ens               Cpus_allowed_list:  1
# Name:  irq/99-i40e-ens               Cpus_allowed_list:  1
# Name:  irq/100-i40e-en               Cpus_allowed_list:  0
# Name:  irq/101-i40e-en               Cpus_allowed_list:  0
# Name:  irq/102-i40e-en               Cpus_allowed_list:  1
# Name:  irq/103-i40e-en               Cpus_allowed_list:  0
# Name:  irq/104-i40e-en               Cpus_allowed_list:  1
# Name:  irq/105-i40e-en               Cpus_allowed_list:  0
# Name:  irq/106-i40e-en               Cpus_allowed_list:  1
# Name:  irq/107-i40e-en               Cpus_allowed_list:  1
# Name:  irq/108-i40e-en               Cpus_allowed_list:  1
# Name:  kworker/2:1-mm_percpu_wq      Cpus_allowed_list:  2
# Name:  migration/2                   Cpus_allowed_list:  2
# Name:  kworker/3:1-events            Cpus_allowed_list:  3
# Name:  kworker/4:1-events            Cpus_allowed_list:  4
# Name:  kworker/5:1-events            Cpus_allowed_list:  5
# Name:  kworker/6:1-mm_percpu_wq      Cpus_allowed_list:  6
# Name:  irq/69-ens81f0n               Cpus_allowed_list:  1
# Name:  irq/70-ens81f0n               Cpus_allowed_list:  1
# Name:  irq/71-ens81f0n               Cpus_allowed_list:  1
# Name:  irq/72-ens81f0n               Cpus_allowed_list:  1
# Name:  irq/73-ens81f0n               Cpus_allowed_list:  1
# Name:  irq/74-ens81f0n               Cpus_allowed_list:  1
# Name:  irq/75-ens81f0n               Cpus_allowed_list:  1
# Name:  kworker/7:1-mm_percpu_wq      Cpus_allowed_list:  7
# Name:  irq/76-ens81f0n               Cpus_allowed_list:  1
# Name:  kworker/8:1-mm_percpu_wq      Cpus_allowed_list:  8
# Name:  kworker/9:1-mm_percpu_wq      Cpus_allowed_list:  9
# Name:  irq/78-ens81f1n               Cpus_allowed_list:  1
# Name:  kworker/10:1-events           Cpus_allowed_list:  10
# Name:  irq/79-ens81f1n               Cpus_allowed_list:  1
# Name:  irq/80-ens81f1n               Cpus_allowed_list:  1
# Name:  irq/81-ens81f1n               Cpus_allowed_list:  1
# Name:  irq/82-ens81f1n               Cpus_allowed_list:  1
# Name:  irq/83-ens81f1n               Cpus_allowed_list:  1
# Name:  irq/84-ens81f1n               Cpus_allowed_list:  1
# Name:  irq/85-ens81f1n               Cpus_allowed_list:  1
# Name:  kworker/11:1-mm_percpu_wq     Cpus_allowed_list:  11
# Name:  kworker/12:1-mm_percpu_wq     Cpus_allowed_list:  12
# Name:  rcuc/2                        Cpus_allowed_list:  2
# Name:  kworker/13:1-mm_percpu_wq     Cpus_allowed_list:  13
# Name:  kworker/14:1-mm_percpu_wq     Cpus_allowed_list:  14
# Name:  kworker/15:1-mm_percpu_wq     Cpus_allowed_list:  15
# Name:  kworker/16:1-mm_percpu_wq     Cpus_allowed_list:  16
# Name:  kworker/17:1-mm_percpu_wq     Cpus_allowed_list:  17
# Name:  kworker/18:1-mm_percpu_wq     Cpus_allowed_list:  18
# Name:  kworker/19:1-mm_percpu_wq     Cpus_allowed_list:  19
# Name:  irq/4-ttyS0                   Cpus_allowed_list:  0
# Name:  ksoftirqd/2                   Cpus_allowed_list:  2
# Name:  rpcbind                       Cpus_allowed_list:  0-1
# Name:  rpc.statd                     Cpus_allowed_list:  0-1
# Name:  kworker/2:0-mm_percpu_wq      Cpus_allowed_list:  2
# Name:  rcu_gp                        Cpus_allowed_list:  0-19
# Name:  kworker/2:0H                  Cpus_allowed_list:  2
# Name:  crio                          Cpus_allowed_list:  0-1
# Name:  kubelet                       Cpus_allowed_list:  0-1
# Name:  rcuog/2                       Cpus_allowed_list:  0-1
# Name:  rcuop/2                       Cpus_allowed_list:  0-1
# Name:  cpuhp/3                       Cpus_allowed_list:  3
# Name:  kthrotld                      Cpus_allowed_list:  0-19
# Name:  watchdog/3                    Cpus_allowed_list:  0-19
# Name:  irq/24-PCIe PME               Cpus_allowed_list:  1
# Name:  irq/26-PCIe PME               Cpus_allowed_list:  1
# Name:  irq/26-pciehp                 Cpus_allowed_list:  1
# Name:  irq/26-s-pciehp               Cpus_allowed_list:  1
# Name:  irq/27-PCIe PME               Cpus_allowed_list:  1
# Name:  irq/65-PCIe PME               Cpus_allowed_list:  0
# Name:  irq/65-aerdrv                 Cpus_allowed_list:  0
# Name:  irq/65-s-aerdrv               Cpus_allowed_list:  0
# Name:  acpi_thermal_pm               Cpus_allowed_list:  0-19
# Name:  kmpath_rdacd                  Cpus_allowed_list:  0-19
# Name:  migration/3                   Cpus_allowed_list:  3
# Name:  kaluad                        Cpus_allowed_list:  0-19
# Name:  irq/66-xhci_hcd               Cpus_allowed_list:  1
# Name:  irq/8-rtc0                    Cpus_allowed_list:  0
# Name:  kworker/0:1H-kblockd          Cpus_allowed_list:  0
# Name:  ipv6_addrconf                 Cpus_allowed_list:  1
# Name:  kstrp                         Cpus_allowed_list:  0-19
# Name:  rcuc/3                        Cpus_allowed_list:  3
# Name:  conmon                        Cpus_allowed_list:  0-1
# Name:  node_exporter                 Cpus_allowed_list:  0-19
# Name:  conmon                        Cpus_allowed_list:  0-1
# Name:  ksoftirqd/3                   Cpus_allowed_list:  3
# Name:  sh                            Cpus_allowed_list:  0-19
# Name:  conmon                        Cpus_allowed_list:  0-1
# Name:  kworker/3:0-mm_percpu_wq      Cpus_allowed_list:  3
# Name:  conmon                        Cpus_allowed_list:  0-1
# Name:  machine-config-               Cpus_allowed_list:  0-19
# Name:  run                           Cpus_allowed_list:  0-19
# Name:  conmon                        Cpus_allowed_list:  0-1
# Name:  opm                           Cpus_allowed_list:  0-19
# Name:  kworker/3:0H                  Cpus_allowed_list:  3
# Name:  conmon                        Cpus_allowed_list:  0-1
# Name:  conmon                        Cpus_allowed_list:  0-1
# Name:  conmon                        Cpus_allowed_list:  0-1
# Name:  bash                          Cpus_allowed_list:  0-19
# Name:  openshift-sdn-n               Cpus_allowed_list:  0-19
# Name:  rcu_par_gp                    Cpus_allowed_list:  0-19
# Name:  rcuop/3                       Cpus_allowed_list:  0-1
# Name:  entrypoint.sh                 Cpus_allowed_list:  0-19
# Name:  cpuhp/4                       Cpus_allowed_list:  4
# Name:  watchdog/4                    Cpus_allowed_list:  0-19
# Name:  migration/4                   Cpus_allowed_list:  4
# Name:  rcuc/4                        Cpus_allowed_list:  4
# Name:  ksoftirqd/4                   Cpus_allowed_list:  4
# Name:  kworker/4:0-mm_percpu_wq      Cpus_allowed_list:  4
# Name:  kworker/4:0H                  Cpus_allowed_list:  4
# Name:  rcuop/4                       Cpus_allowed_list:  0-1
# Name:  cpuhp/5                       Cpus_allowed_list:  5
# Name:  watchdog/5                    Cpus_allowed_list:  0-19
# Name:  migration/5                   Cpus_allowed_list:  5
# Name:  rcuc/5                        Cpus_allowed_list:  5
# Name:  ksoftirqd/5                   Cpus_allowed_list:  5
# Name:  conmon                        Cpus_allowed_list:  0-1
# Name:  opm                           Cpus_allowed_list:  0-19
# Name:  kworker/5:0-mm_percpu_wq      Cpus_allowed_list:  5
# Name:  kworker/5:0H                  Cpus_allowed_list:  5
# Name:  openshift-tuned               Cpus_allowed_list:  0-19
# Name:  rcuog/5                       Cpus_allowed_list:  0-1
# Name:  polkitd                       Cpus_allowed_list:  0-1
# Name:  iscsi_eh                      Cpus_allowed_list:  0-19
# Name:  iscsi_destroy                 Cpus_allowed_list:  0-19
# Name:  rcuop/5                       Cpus_allowed_list:  0-1
# Name:  cpuhp/6                       Cpus_allowed_list:  6
# Name:  journalctl                    Cpus_allowed_list:  0-19
# Name:  watchdog/6                    Cpus_allowed_list:  0-19
# Name:  kworker/0:0H-events_highpri   Cpus_allowed_list:  0
# Name:  migration/6                   Cpus_allowed_list:  6
# Name:  rcuc/6                        Cpus_allowed_list:  6
# Name:  ksoftirqd/6                   Cpus_allowed_list:  6
# Name:  kworker/6:0-mm_percpu_wq      Cpus_allowed_list:  6
# Name:  kworker/6:0H                  Cpus_allowed_list:  6
# Name:  rcuop/6                       Cpus_allowed_list:  0-1
# Name:  cpuhp/7                       Cpus_allowed_list:  7
# Name:  cnic_wq                       Cpus_allowed_list:  0-19
# Name:  bnx2i_thread/0                Cpus_allowed_list:  0
# Name:  bnx2i_thread/1                Cpus_allowed_list:  1
# Name:  watchdog/7                    Cpus_allowed_list:  0-19
# Name:  bnx2i_thread/2                Cpus_allowed_list:  2
# Name:  bnx2i_thread/3                Cpus_allowed_list:  3
# Name:  bnx2i_thread/4                Cpus_allowed_list:  4
# Name:  bnx2i_thread/5                Cpus_allowed_list:  5
# Name:  bnx2i_thread/6                Cpus_allowed_list:  6
# Name:  bnx2i_thread/7                Cpus_allowed_list:  7
# Name:  bnx2i_thread/8                Cpus_allowed_list:  8
# Name:  bnx2i_thread/9                Cpus_allowed_list:  9
# Name:  bnx2i_thread/10               Cpus_allowed_list:  10
# Name:  bnx2i_thread/11               Cpus_allowed_list:  11
# Name:  tuned                         Cpus_allowed_list:  0-19
# Name:  migration/7                   Cpus_allowed_list:  7
# Name:  bnx2i_thread/12               Cpus_allowed_list:  12
# Name:  bnx2i_thread/13               Cpus_allowed_list:  13
# Name:  bnx2i_thread/14               Cpus_allowed_list:  14
# Name:  bnx2i_thread/15               Cpus_allowed_list:  15
# Name:  bnx2i_thread/16               Cpus_allowed_list:  16
# Name:  bnx2i_thread/17               Cpus_allowed_list:  17
# Name:  bnx2i_thread/18               Cpus_allowed_list:  18
# Name:  bnx2i_thread/19               Cpus_allowed_list:  19
# Name:  rcuc/7                        Cpus_allowed_list:  7
# Name:  irqbalance                    Cpus_allowed_list:  0-1
# Name:  stalld                        Cpus_allowed_list:  0-1
# Name:  ksoftirqd/7                   Cpus_allowed_list:  7
# Name:  kworker/7:0-mm_percpu_wq      Cpus_allowed_list:  7
# Name:  conmon                        Cpus_allowed_list:  0-1
# Name:  conmon                        Cpus_allowed_list:  0-1
# Name:  kube-rbac-proxy               Cpus_allowed_list:  0-19
# Name:  coredns                       Cpus_allowed_list:  0-19
# Name:  kworker/7:0H                  Cpus_allowed_list:  7
# Name:  kmpathd                       Cpus_allowed_list:  0-19
# Name:  conmon                        Cpus_allowed_list:  0-1
# Name:  kmpath_handlerd               Cpus_allowed_list:  0-19
# Name:  kube-rbac-proxy               Cpus_allowed_list:  0-19
# Name:  conmon                        Cpus_allowed_list:  0-1
# Name:  conmon                        Cpus_allowed_list:  0-1
# Name:  conmon                        Cpus_allowed_list:  0-1
# Name:  rcuop/7                       Cpus_allowed_list:  0-1
# Name:  oauth-proxy                   Cpus_allowed_list:  0-19
# Name:  conmon                        Cpus_allowed_list:  0-1
# Name:  cluster-network               Cpus_allowed_list:  0-19
# Name:  ingress-operato               Cpus_allowed_list:  0-19
# Name:  cpuhp/8                       Cpus_allowed_list:  8
# Name:  network-metrics               Cpus_allowed_list:  0-19
# Name:  watchdog/8                    Cpus_allowed_list:  0-19
# Name:  migration/8                   Cpus_allowed_list:  8
# Name:  rcuc/8                        Cpus_allowed_list:  8
# Name:  ksoftirqd/8                   Cpus_allowed_list:  8
# Name:  kworker/8:0-mm_percpu_wq      Cpus_allowed_list:  8
# Name:  conmon                        Cpus_allowed_list:  0-1
# Name:  kworker/8:0H                  Cpus_allowed_list:  8
# Name:  kube-rbac-proxy               Cpus_allowed_list:  0-19
# Name:  rcuop/8                       Cpus_allowed_list:  0-1
# Name:  ata_sff                       Cpus_allowed_list:  0-19
# Name:  irq/67-ahci[000               Cpus_allowed_list:  1
# Name:  cpuhp/9                       Cpus_allowed_list:  9
# Name:  scsi_eh_0                     Cpus_allowed_list:  0-1
# Name:  scsi_eh_1                     Cpus_allowed_list:  0-1
# Name:  scsi_tmf_0                    Cpus_allowed_list:  0-19
# Name:  bnxt_pf_wq                    Cpus_allowed_list:  0-19
# Name:  usb-storage                   Cpus_allowed_list:  0-1
# Name:  scsi_tmf_1                    Cpus_allowed_list:  0-19
# Name:  watchdog/9                    Cpus_allowed_list:  0-19
# Name:  scsi_eh_2                     Cpus_allowed_list:  0-1
# Name:  scsi_tmf_2                    Cpus_allowed_list:  0-19
# Name:  i40e                          Cpus_allowed_list:  0
# Name:  uas                           Cpus_allowed_list:  0-19
# Name:  scsi_eh_3                     Cpus_allowed_list:  0-1
# Name:  scsi_tmf_3                    Cpus_allowed_list:  0-19
# Name:  scsi_eh_4                     Cpus_allowed_list:  0-1
# Name:  scsi_tmf_4                    Cpus_allowed_list:  0-19
# Name:  migration/9                   Cpus_allowed_list:  9
# Name:  scsi_eh_5                     Cpus_allowed_list:  0-1
# Name:  scsi_tmf_5                    Cpus_allowed_list:  0-19
# Name:  scsi_eh_6                     Cpus_allowed_list:  0-1
# Name:  scsi_tmf_6                    Cpus_allowed_list:  0-19
# Name:  rcuc/9                        Cpus_allowed_list:  9
# Name:  irq/88-ahci[000               Cpus_allowed_list:  1
# Name:  irq/109-i40e-00               Cpus_allowed_list:  0
# Name:  conmon                        Cpus_allowed_list:  0-1
# Name:  irq/87-i40e-000               Cpus_allowed_list:  0
# Name:  scsi_eh_7                     Cpus_allowed_list:  0-1
# Name:  kube-rbac-proxy               Cpus_allowed_list:  0-19
# Name:  scsi_tmf_7                    Cpus_allowed_list:  0-19
# Name:  ksoftirqd/9                   Cpus_allowed_list:  9
# Name:  scsi_eh_8                     Cpus_allowed_list:  0-1
# Name:  scsi_tmf_8                    Cpus_allowed_list:  0-19
# Name:  scsi_eh_9                     Cpus_allowed_list:  0-1
# Name:  ib-comp-wq                    Cpus_allowed_list:  0-19
# Name:  scsi_tmf_9                    Cpus_allowed_list:  0-19
# Name:  kworker/u41:0                 Cpus_allowed_list:  0-1
# Name:  ib-comp-unb-wq                Cpus_allowed_list:  0-19
# Name:  scsi_eh_10                    Cpus_allowed_list:  0-1
# Name:  ib_mcast                      Cpus_allowed_list:  0-19
# Name:  ib_nl_sa_wq                   Cpus_allowed_list:  0-19
# Name:  kworker/9:0-mm_percpu_wq      Cpus_allowed_list:  9
# Name:  scsi_tmf_10                   Cpus_allowed_list:  0-19
# Name:  scsi_eh_11                    Cpus_allowed_list:  0-1
# Name:  scsi_tmf_11                   Cpus_allowed_list:  0-19
# Name:  scsi_eh_12                    Cpus_allowed_list:  0-1
# Name:  scsi_tmf_12                   Cpus_allowed_list:  0-19
# Name:  scsi_eh_13                    Cpus_allowed_list:  0-1
# Name:  scsi_tmf_13                   Cpus_allowed_list:  0-19
# Name:  scsi_eh_14                    Cpus_allowed_list:  0-1
# Name:  scsi_tmf_14                   Cpus_allowed_list:  0-19
# Name:  kworker/9:0H                  Cpus_allowed_list:  9
# Name:  irq/139-i40e-00               Cpus_allowed_list:  0
# Name:  irq/118-i40e-00               Cpus_allowed_list:  1
# Name:  bnxt_re                       Cpus_allowed_list:  0-19
# Name:  irq/148-bnxt_qp               Cpus_allowed_list:  0
# Name:  bnxt_qplib_nq                 Cpus_allowed_list:  0-19
# Name:  irq/149-bnxt_qp               Cpus_allowed_list:  1
# Name:  bnxt_qplib_nq                 Cpus_allowed_list:  0-19
# Name:  irq/150-bnxt_qp               Cpus_allowed_list:  1
# Name:  rcuop/9                       Cpus_allowed_list:  0-1
# Name:  bnxt_qplib_nq                 Cpus_allowed_list:  0-19
# Name:  irq/151-bnxt_qp               Cpus_allowed_list:  1
# Name:  bnxt_qplib_nq                 Cpus_allowed_list:  0-19
# Name:  irq/152-bnxt_qp               Cpus_allowed_list:  1
# Name:  bnxt_qplib_nq                 Cpus_allowed_list:  0-19
# Name:  irq/153-bnxt_qp               Cpus_allowed_list:  1
# Name:  bnxt_qplib_nq                 Cpus_allowed_list:  0-19
# Name:  irq/154-bnxt_qp               Cpus_allowed_list:  1
# Name:  bnxt_qplib_nq                 Cpus_allowed_list:  0-19
# Name:  irq/155-bnxt_qp               Cpus_allowed_list:  1
# Name:  mm_percpu_wq                  Cpus_allowed_list:  0-19
# Name:  cpuhp/10                      Cpus_allowed_list:  10
# Name:  bnxt_qplib_nq                 Cpus_allowed_list:  0-19
# Name:  irq/156-bnxt_qp               Cpus_allowed_list:  1
# Name:  irq/157-bnxt_qp               Cpus_allowed_list:  1
# Name:  bnxt_qplib_nq                 Cpus_allowed_list:  0-19
# Name:  irq/158-bnxt_qp               Cpus_allowed_list:  0
# Name:  bnxt_qplib_nq                 Cpus_allowed_list:  0-19
# Name:  watchdog/10                   Cpus_allowed_list:  0-19
# Name:  irq/159-bnxt_qp               Cpus_allowed_list:  1
# Name:  bnxt_qplib_nq                 Cpus_allowed_list:  0-19
# Name:  irq/160-bnxt_qp               Cpus_allowed_list:  0
# Name:  bnxt_qplib_nq                 Cpus_allowed_list:  0-19
# Name:  irq/161-bnxt_qp               Cpus_allowed_list:  0
# Name:  bnxt_qplib_nq                 Cpus_allowed_list:  0-19
# Name:  irq/162-bnxt_qp               Cpus_allowed_list:  0
# Name:  bnxt_qplib_nq                 Cpus_allowed_list:  0-19
# Name:  migration/10                  Cpus_allowed_list:  10
# Name:  irq/163-bnxt_qp               Cpus_allowed_list:  0
# Name:  bnxt_qplib_nq                 Cpus_allowed_list:  0-19
# Name:  irq/164-bnxt_qp               Cpus_allowed_list:  0
# Name:  bnxt_qplib_nq                 Cpus_allowed_list:  0-19
# Name:  irq/165-bnxt_qp               Cpus_allowed_list:  0
# Name:  rcuc/10                       Cpus_allowed_list:  10
# Name:  ib_mad1                       Cpus_allowed_list:  0-19
# Name:  ib_mad1                       Cpus_allowed_list:  0-19
# Name:  ksoftirqd/10                  Cpus_allowed_list:  10
# Name:  kworker/10:0-mm_percpu_wq     Cpus_allowed_list:  10
# Name:  rdma_cm                       Cpus_allowed_list:  0-19
# Name:  kworker/10:0H                 Cpus_allowed_list:  10
# Name:  target_completi               Cpus_allowed_list:  0-19
# Name:  xcopy_wq                      Cpus_allowed_list:  0-19
# Name:  rcuog/10                      Cpus_allowed_list:  0-1
# Name:  rcuop/10                      Cpus_allowed_list:  0-1
# Name:  cpuhp/11                      Cpus_allowed_list:  11

```

# troubleshooting
```bash
oc project openshift-cluster-node-tuning-operator


find /proc/irq/ -name smp_affinity_list -exec sh -c 'i="$1"; mask=$(cat $i); file=$(echo $i); echo $file: $mask' _ {} \;

```