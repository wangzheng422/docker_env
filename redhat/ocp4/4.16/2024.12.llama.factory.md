# running llama factory using ray on openshift ai


# build image

on vm, with 16C 32G.

```bash

# download the model first
dnf install -y conda


mkdir -p /data/env/
conda create -y -p /data/env/hg_cli python=3.11

conda init bash

conda activate /data/env/hg_cli
# conda deactivate

# python -m pip install --upgrade pip setuptools wheel

pip install --upgrade huggingface_hub


# for Maykeye/TinyLLama-v0
VAR_NAME=Maykeye/TinyLLama-v0

VAR_NAME_FULL=${VAR_NAME//\//-}
echo $VAR_NAME_FULL
# THUDM-ChatGLM2-6B

mkdir -p /data/huggingface/${VAR_NAME_FULL}
cd /data/huggingface/${VAR_NAME_FULL}

while true; do
    huggingface-cli download --repo-type model --revision main --cache-dir /data/huggingface/cache --local-dir ./ --local-dir-use-symlinks False --exclude "*.pt"  --resume-download ${VAR_NAME} 
    if [ $? -eq 0 ]; then
        break
    fi
    sleep 1  # Optional: waits for 1 second before trying again
done


# install and try llama factory
mkdir -p /data/git
cd /data/git

git clone -b wzh https://github.com/wangzheng422/LLaMA-Factory

cd /data/git/LLaMA-Factory

pip install -e ".[torch,metrics]"


/bin/rm -rf saves/tinyllama
llamafactory-cli train wzh/tinyllama_lora_sft.yaml



```

# run multiple instance using deployment on ocp


# end